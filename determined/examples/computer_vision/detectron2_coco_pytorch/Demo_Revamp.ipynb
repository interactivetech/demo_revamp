{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a75ea8c-ac73-4b71-ac96-c39ecafc79cf",
   "metadata": {},
   "source": [
    "# Demo Revamp\n",
    "* Swappable Datasets\n",
    "* Swappable Model Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88aa0b0e-abb7-437c-8997-1be3d12b722e",
   "metadata": {},
   "source": [
    "# Download Dataset (If have not done already)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afe15bd-0326-4fc3-a9cf-f9ad24cfc23f",
   "metadata": {},
   "source": [
    "```bash\n",
    "python download_datasets.py --dataset-dir /run/determined/workdir/shared_fs/data/ --key <API_KEY>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57a9696-cdd4-48a9-a0ad-8fe65cc5a7f4",
   "metadata": {},
   "source": [
    "# Dataset 1: Public Sector - FLIR Object Detection Dataset\n",
    "* Details: Dataset of moving objects taken from near infared thermal camera , to aid in self-driving and autonomous vehicles.https://universe.roboflow.com/thermal-imaging-0hwfw/flir-data-set\n",
    "* Classes: (cars, bicycles, people, and dogs)\n",
    "<img title=\"FLIR Image Example\" src=\"https://storage.googleapis.com/roboflow-platform-sources/v2ONhxR3iuHqgfOUfmjO/5MjAkaP42DwQAO26W3em/original.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399fc396-23f4-48ea-82f3-7ab972e21fcf",
   "metadata": {},
   "source": [
    "# MaskRCNN\n",
    "<img title=\"MaskRCNN\" src=\"https://production-media.paperswithcode.com/methods/Screen_Shot_2020-05-23_at_7.44.34_PM.png\">\n",
    "* Developed by Facebook Research (2019) Mask R-CNN extends Faster R-CNN to solve instance segmentation tasks. It achieves this by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. In principle, Mask R-CNN is an intuitive extension of Faster R-CNN, but constructing the mask branch properly is critical for good results.\n",
    "\n",
    "* Most importantly, Faster R-CNN was not designed for pixel-to-pixel alignment between network inputs and outputs. This is evident in how RoIPool, the de facto core operation for attending to instances, performs coarse spatial quantization for feature extraction. To fix the misalignment, Mask R-CNN utilises a simple, quantization-free layer, called RoIAlign, that faithfully preserves exact spatial locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d508d27-103b-40bf-9ee7-1ff2c02a98d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: detectron2_const_maskrcnn_flir\n",
      "environment:\n",
      "    image: \"determinedai/example-detectron2:0.6-cuda-10.2-pytorch-1.10\"\n",
      "hyperparameters:\n",
      "  global_batch_size: 32 # Detectron defaults to 16 regardless of N GPUs\n",
      "  model_yaml: models/mask_rcnn_R_50_FPN_noaug_1x.yaml\n",
      "  dataset_name: 'flir-camera-objects'\n",
      "  output_dir: None\n",
      "  fake_data: False\n",
      "searcher:\n",
      "  name: single\n",
      "  metric: bboxAP\n",
      "  max_length: \n",
      "    batches: 9000\n",
      "  smaller_is_better: false\n",
      "resources:\n",
      "    slots_per_trial: 4\n",
      "entrypoint: model_def:DetectronTrial\n",
      "max_restarts: 0\n",
      "min_validation_period:\n",
      "  batches: 100\n"
     ]
    }
   ],
   "source": [
    "# YAML File Defining training Mask RCNN on FLIR DATASET \n",
    "!cat configs/flir_training/const_maskrcnn_flir.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ce376b-d083-47f2-a232-7b61ccf7a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1a134f0-6dd6-4a40-b175-8956060dd590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing files to send to master... 2.8MB and 83 files  \n",
      "Created experiment 810\n"
     ]
    }
   ],
   "source": [
    "# Train MaskRCNN model on FLIR Object Detection Dataset\n",
    "!det e create configs/flir_training/const_maskrcnn_flir.yaml ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b296a6b-bc38-4639-9ba1-998cc369be9b",
   "metadata": {},
   "source": [
    "# FasterRCNN\n",
    "<img title=\"FasterRCNN\" src=\"https://production-media.paperswithcode.com/methods/new_arch.jpg\">\n",
    "* Developed by Microsoft Research (2015). It is an improvement over the earlier R-CNN and Fast R-CNN algorithms. It uses a region proposal network (RPN) to generate a set of object proposals, which are then fed into a convolutional neural network (CNN) for classification and bounding box regression. The RPN shares convolutional layers with the CNN, making the algorithm more efficient and faster than its predecessors. The end result is a highly accurate and efficient object detection system that can detect and classify objects in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb9d6bac-4636-4eed-b56b-2fd3ac5f06e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: detectron2_const_fasterrcnn_flir\n",
      "environment:\n",
      "    image: \"determinedai/example-detectron2:0.6-cuda-10.2-pytorch-1.10\"\n",
      "hyperparameters:\n",
      "  global_batch_size: 8 # Detectron defaults to 16 regardless of N GPUs\n",
      "  model_yaml: models/fast_rcnn_R_50_FPN_1x.yaml\n",
      "  dataset_name: 'flir-camera-objects'\n",
      "  output_dir: None\n",
      "  fake_data: False\n",
      "searcher:\n",
      "  name: single\n",
      "  metric: bboxAP\n",
      "  max_length: \n",
      "    batches: 9000\n",
      "  smaller_is_better: false\n",
      "resources:\n",
      "    slots_per_trial: 4\n",
      "entrypoint: model_def:DetectronTrial\n",
      "max_restarts: 0\n",
      "min_validation_period:\n",
      "  batches: 100\n"
     ]
    }
   ],
   "source": [
    "# YAML File Defining training FasterRCNN on FLIR DATASET \n",
    "!cat configs/flir_training/const_fasterrcnn_flir.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d40178f-b48d-4670-a0d5-85309fe22072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing files to send to master... 2.8MB and 83 files  \n",
      "Created experiment 803\n"
     ]
    }
   ],
   "source": [
    "# Train FasterRCNN model on FLIR Object Detection Dataset\n",
    "!det e create configs/flir_training/const_fasterrcnn_flir.yaml . "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abe0f98-add6-4f14-9108-bd4ffea87836",
   "metadata": {},
   "source": [
    "# Dataset 2: Healthcare Dataset - Dataset to detect \n",
    "* Details: X class dataset, objects are different bones in the hand. Intention of dataset is to identify bone regions in the hand, and examine if Rheumatology is occuring. https://universe.roboflow.com/roboflow-100/x-ray-rheumatology\n",
    "* Classes: artefact, distal phalanges, fifth metacarpal bone, first metacarpal bone, fourth metacarpal bone, intermediate phalanges, proximal phalanges, radius, second metacarpal bone, soft tissue calcination, third metacarpal bone, ulna\n",
    "<img title=\"FLIR Image Example\" src=\"https://storage.googleapis.com/roboflow-platform-sources/pwYAXv9BTpqLyFfgQoPZ/MUGCCUn087IBqjXlfCJB/original.jpg\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885a4b33-c62b-4673-9526-3c4ff89f8219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YAML File Defining training Mask RCNN on XRAY DATASET \n",
    "!cat configs/xray_training/const_maskrcnn_xray.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750bb0a1-eb6e-4052-932c-78050681a410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MaskRCNN model on XRAY Object Detection Dataset\n",
    "!det e create configs/flir_training/const_maskrcnn_flir.yaml . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73655f3-3131-4947-8a37-20600a2a59ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YAML File Defining training FasterRCNN on XRAY DATASET \n",
    "!cat configs/xray_training/const_fasterrcnn_xray.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05eee86-6e3b-4ff8-a94c-9c560255844a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train FasterRCNN model on XRAY Object Detection Dataset\n",
    "!det e create configs/flir_training/const_fasterrcnn_flir.yaml . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e6d3af-e843-4c62-83b6-29371e82e524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
