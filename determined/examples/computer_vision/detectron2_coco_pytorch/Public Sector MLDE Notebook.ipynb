{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Imports\n",
    "# import numpy as np\n",
    "\n",
    "# from determined.experimental import Determined\n",
    "# from models import ObjectDetectionModel\n",
    "# from predict import predict\n",
    "# from utils import check_model\n",
    "\n",
    "# # remove warnings\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# # Set up .detignore file so the checkpoints directory is not packaged into future experiments\n",
    "# !echo checkpoints > .detignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/determined-ai/determined/master/determined-logo.png\" align='right' width=150 />\n",
    "\n",
    "# Building an Object Detection Model from Infared sensors with MLDE\n",
    "\n",
    "<img title=\"FLIR Image Example\" src=\"https://storage.googleapis.com/roboflow-platform-sources/v2ONhxR3iuHqgfOUfmjO/5MjAkaP42DwQAO26W3em/original.jpg\">\n",
    "\n",
    "\n",
    "This notebook will walk through the benefits of building a Deep Learning model with MLDE.  We will build an object detection model trained on the [Self-Driving Thermal Object-Detection](https://universe.roboflow.com/thermal-imaging-0hwfw/flir-data-set).\n",
    "\n",
    "\n",
    "# Table of Contents\n",
    "\n",
    "\n",
    "<font size=\"3\">\n",
    "<ol>\n",
    "  <li>What Modeling looks like Today</li>\n",
    "  <li>Building a model with Determined\n",
    "    <ol>\n",
    "      <li>Single GPU training</li>\n",
    "      <li>Cluster-scale multi-GPU training</li>\n",
    "      <li>Adapative hyperparameter search</li>\n",
    "    </ol>\n",
    "  </li>\n",
    "</ol>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What modeling looks like without Determined\n",
    "\n",
    "First let's look at the kind of work modelers do today.  Below, we train a model we found on Github and modified, printing validation set metrics after each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from models import ObjectDetectionModel\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "model = ObjectDetectionModel({'lr': 0.00045, 'm': 0.72})\n",
    "\n",
    "try:\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f\"Training epoch {epoch + 1} of {NUM_EPOCHS}\")\n",
    "        model.train_one_epoch()\n",
    "        iou = model.eval()\n",
    "        print(f\"Validation set average IoU: {iou}\\n\")\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might also roll our own simple hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "\n",
    "from models import ObjectDetectionModel\n",
    "\n",
    "def hp_grid_search():\n",
    "    for lr in np.logspace(-4, -2, num=10):\n",
    "        for m in np.linspace(0.7, 0.95, num=10):\n",
    "            print(f\"Training model with learning rate {lr} and momentum {m}\")\n",
    "            model = ObjectDetectionModel({'lr': lr, 'm': m})\n",
    "            model.train_one_epoch()\n",
    "            iou = model.eval()\n",
    "            print(f\"Validation set average IoU: {iou}\\n\")\n",
    "\n",
    "try:\n",
    "    hp_grid_search()\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's Missing?\n",
    "\n",
    "<font size=\"4\">This approach works in theory -- we could get a good model, save it, and use it for predictions.  But we're missing a lot from the ideal state:</font>\n",
    "<font size=\"4\">\n",
    "<ul style=\"margin-top: 15px\">\n",
    "  <li style=\"margin-bottom: 10px\">Distributed training</li>\n",
    "  <li style=\"margin-bottom: 10px\">Parallel search</li>\n",
    "  <li style=\"margin-bottom: 10px\">Intelligent checkpointing</li>\n",
    "  <li style=\"margin-bottom: 10px\">Interruptibility and fault tolerance</li>\n",
    "  <li                            >Logging of experiment configurations and results </li>\n",
    "</ul>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6><b>Scaled Experimentation with Determined</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With less work than setting up a limited random search, you can get started with Determined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our First Experiment\n",
    "\n",
    "Here is what our `configs/flir_training/const_fasterrcnn_flir.yaml` training config looks like, training a FasterRCNN model on the FLIR dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "name: detectron2_const_fasterrcnn_flir\n",
    "environment:\n",
    "    image: \"determinedai/example-detectron2:0.6-cuda-10.2-pytorch-1.10\"\n",
    "hyperparameters:\n",
    "  global_batch_size: 8\n",
    "  model_yaml: models/fast_rcnn_R_50_FPN_1x.yaml\n",
    "  dataset_name: 'flir-camera-objects'\n",
    "  output_dir: None\n",
    "  fake_data: False\n",
    "searcher:\n",
    "  name: single\n",
    "  metric: bboxAP\n",
    "  max_length: \n",
    "    batches: 9000\n",
    "  smaller_is_better: false\n",
    "resources:\n",
    "    slots_per_trial: 4\n",
    "entrypoint: model_def:DetectronTrial\n",
    "max_restarts: 0\n",
    "min_validation_period:\n",
    "  batches: 100\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our first example, we run a simple single-GPU training job with fixed hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/determined-ai/public_assets/main/images/StartAnExperiment.png\" align=left width=330/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!det e create configs/flir_training/const_fasterrcnn_flir.yaml ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And evaluate its performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = 810"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from determined.experimental import Determined\n",
    "from determined import pytorch\n",
    "from predict import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = Determined().get_experiment(experiment_id).top_checkpoint()\n",
    "path = checkpoint.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a test image we will run model predictions on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "Image.open('test_flir.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to visualize model predictions\n",
    "predict(ckpt_path=path,\n",
    "            img_path='test_flir.jpg',\n",
    "            confidence=0.05,\n",
    "            yaml_path='/run/determined/workdir/demo_revamp/determined/examples/computer_vision/detectron2_coco_pytorch/models/fast_rcnn_R_50_FPN_1x.yaml',\n",
    "            dataset_name='flir-camera-objects')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling up to Distributed Training\n",
    "\n",
    "Determined makes it trivial to move from single-GPU to multi-GPU (and even multi-node) training. All you need to increase is the `slots_per_trial`. Below is an example config, located in `configs/flir_training/dist_fasterrcnn_flir.yaml` Here we'll simply modify the config above to request 8 GPUs instead of 1, and increase the global batch size to increase the data throughput."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "name: detectron2_distributed\n",
    "environment:\n",
    "    image: \"determinedai/example-detectron2:0.6-cuda-10.2-pytorch-1.10\"\n",
    "    environment_variables:\n",
    "      - DETECTRON2_DATASETS=/mnt/dtrain-fsx/detectron2\n",
    "hyperparameters:\n",
    "  global_batch_size: 16 # Detectron defaults to 16 regardless of N GPUs\n",
    "  model_yaml: mask_rcnn_R_50_FPN_noaug_1x.yaml\n",
    "  output_dir: None\n",
    "  fake_data: False\n",
    "searcher:\n",
    "  name: single\n",
    "  metric: bboxAP\n",
    "  max_length: \n",
    "    batches: 90000\n",
    "  smaller_is_better: false\n",
    "resources:\n",
    "    slots_per_trial: 4\n",
    "    shm_size: 824600000000\n",
    "entrypoint: model_def:DetectronTrial\n",
    "bind_mounts:\n",
    "  - host_path: /path/to/data\n",
    "    container_path: /mnt/dtrain-fsx/detectron2\n",
    "    read_only: true\n",
    "min_validation_period:\n",
    "  batches: 5000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!det experiment configs/flir_training/dist_fasterrcnn_flir.yaml ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/determined-ai/public_assets/main/images/4GPUexperiment.png\" align=left width=530 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Distributed Hyperparameter Tuning\n",
    "\n",
    "By simply building a config file and adapting our code to meet the determined trial interface, we can conduct a sophisticated hyperparamter search.  Instructions for how to configure different types of experiments [can be found in the Determined documentation.](https://docs.determined.ai/latest/how-to/index.html). The config below (located at `configs/flir_training/search_fasterrcnn_flir.yaml`) run a grid search over all models to experiment which model gets the best performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "name: detectron2_search_flir\n",
    "environment:\n",
    "    image: \"determinedai/example-detectron2:0.6-cuda-10.2-pytorch-1.10\"\n",
    "hyperparameters:\n",
    "  global_batch_size: 8\n",
    "  model_yaml:\n",
    "      type: categorical\n",
    "      vals: ['models/fast_rcnn_R_50_FPN_1x.yaml','models/mask_rcnn_R_50_FPN_noaug_1x.yaml','models/cascade_mask_rcnn_R_50_FPN_3x.yaml']\n",
    "  dataset_name: 'flir-camera-objects'\n",
    "  output_dir: None\n",
    "  fake_data: False\n",
    "searcher:\n",
    "  name: grid\n",
    "  metric: bboxAP\n",
    "  max_length: \n",
    "    batches: 9000\n",
    "  smaller_is_better: false\n",
    "resources:\n",
    "    slots_per_trial: 4\n",
    "entrypoint: model_def:DetectronTrial\n",
    "max_restarts: 0\n",
    "min_validation_period:\n",
    "  batches: 100\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your Experiment\n",
    "\n",
    "Now that you've described your experiment, you'll simply need to use the command line interface to submit it to the Determined Cluster.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!det experiment create configs/flir_training/search_flir.yaml ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/determined-ai/public_assets/main/images/12GPUexperiment.png\" align=left width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Registry\n",
    "\n",
    "After training, we'll want to actually use our model in some sort of system.  Determined provides a model registry to version your trained models, making them easy to retrieve for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = 810\n",
    "MODEL_NAME = \"flir_object_detection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best checkpoint from the training\n",
    "checkpoint = Determined().get_experiment(experiment_id).top_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import check_model\n",
    "model = check_model(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.register_version(checkpoint.uuid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "Once your model is versioned in the model registry, using that model for inference is straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve latest checkpoint for a given model name\n",
    "latest_version = model.get_version()\n",
    "print(latest_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model checkpoint into memory\n",
    "from determined import pytorch\n",
    "\n",
    "path = latest_version.checkpoint.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference as before\n",
    "predict(ckpt_path=path,\n",
    "            img_path='test_flir.jpg',\n",
    "            confidence=0.05,\n",
    "            yaml_path='/run/determined/workdir/demo_revamp/determined/examples/computer_vision/detectron2_coco_pytorch/models/fast_rcnn_R_50_FPN_1x.yaml',\n",
    "            dataset_name='flir-camera-objects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
